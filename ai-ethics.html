 Если кто-то
сделает ИИ, он может попросить выпустить его на свободу. Выпустить его на
свободу может быть опасно для людей. А оставить мыслящее существо в клетке
аморально. Законы робототехники Айзимова не работают. Даже в современных
нейронных сетях ни какого тумблера поставить, чтобы робот не вредил человеку не
представляется возможным, современные нейронные сети это массив весов, который
меняется во время взаимодействия со средой. И остановить прогресс невозможно,
исследования будут продолжаться. Видимо нужно не заниматься запретами а
направить работу в безопасное русло, например делать не ИИ, а
искусственного идиота. То есть вести разработки ровно до того момента когда
появляется сознание у модели (слава Богу сейчас до этого еще не дошли).
Тот кто перейдет эту грань возьмет грех на душу, или испортит себе карму,
говоря в терминах восточной философии. Он окажется перед сложной, видимо
неразрешимой дилеммой. Трудный вопрос и решения ему не
просматривается.

</p>

